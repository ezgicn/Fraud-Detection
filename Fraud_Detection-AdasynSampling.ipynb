{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\en\\anaconda3\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\en\\anaconda3\\lib\\site-packages (from xgboost) (1.5.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\en\\anaconda3\\lib\\site-packages (from xgboost) (1.18.5)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statistics\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn import metrics, datasets, preprocessing, model_selection, svm, naive_bayes, neighbors, ensemble\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, precision_recall_curve,f1_score, roc_auc_score, roc_curve, plot_roc_curve\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "!pip install xgboost\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'C:/Users/EN/DataScienceAcademy/Project5/creditcard.csv'\n",
    "df=pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rob_scaler = RobustScaler()\n",
    "\n",
    "df['scaled_amount'] = rob_scaler.fit_transform(df['Amount'].values.reshape(-1,1))\n",
    "df['scaled_time'] = rob_scaler.fit_transform(df['Time'].values.reshape(-1,1))\n",
    "\n",
    "df.drop(['Time','Amount'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>scaled_time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.783274</td>\n",
       "      <td>-0.994983</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.269825</td>\n",
       "      <td>-0.994983</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.983721</td>\n",
       "      <td>-0.994972</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.418291</td>\n",
       "      <td>-0.994972</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.670579</td>\n",
       "      <td>-0.994960</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   scaled_amount  scaled_time        V1        V2        V3        V4  \\\n",
       "0       1.783274    -0.994983 -1.359807 -0.072781  2.536347  1.378155   \n",
       "1      -0.269825    -0.994983  1.191857  0.266151  0.166480  0.448154   \n",
       "2       4.983721    -0.994972 -1.358354 -1.340163  1.773209  0.379780   \n",
       "3       1.418291    -0.994972 -0.966272 -0.185226  1.792993 -0.863291   \n",
       "4       0.670579    -0.994960 -1.158233  0.877737  1.548718  0.403034   \n",
       "\n",
       "         V5        V6        V7        V8  ...       V20       V21       V22  \\\n",
       "0 -0.338321  0.462388  0.239599  0.098698  ...  0.251412 -0.018307  0.277838   \n",
       "1  0.060018 -0.082361 -0.078803  0.085102  ... -0.069083 -0.225775 -0.638672   \n",
       "2 -0.503198  1.800499  0.791461  0.247676  ...  0.524980  0.247998  0.771679   \n",
       "3 -0.010309  1.247203  0.237609  0.377436  ... -0.208038 -0.108300  0.005274   \n",
       "4 -0.407193  0.095921  0.592941 -0.270533  ...  0.408542 -0.009431  0.798278   \n",
       "\n",
       "        V23       V24       V25       V26       V27       V28  Class  \n",
       "0 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053      0  \n",
       "1  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724      0  \n",
       "2  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0  \n",
       "3 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458      0  \n",
       "4 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_amount = df['scaled_amount']\n",
    "scaled_time = df['scaled_time']\n",
    "df.drop(['scaled_amount', 'scaled_time'], axis=1, inplace=True)\n",
    "df.insert(0, 'scaled_amount', scaled_amount)\n",
    "df.insert(1, 'scaled_time', scaled_time)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Removing Outliers\n",
    "#V2\n",
    "v2_fraud = df['V2'].loc[df['Class'] == 1].values\n",
    "q25, q75 = np.percentile(v2_fraud, 25), np.percentile(v2_fraud, 75)\n",
    "v2_iqr = q75 - q25\n",
    "v2_cut_off = v2_iqr * 1.5\n",
    "v2_lower, v2_upper = q25 - v2_cut_off, q75 + v2_cut_off\n",
    "outliers = [x for x in v2_fraud if x < v2_lower or x > v2_upper]\n",
    "df = df.drop(df[(df['V2'] > v2_upper) | (df['V2'] < v2_lower)].index)\n",
    "\n",
    "##V3\n",
    "v3_fraud = df['V3'].loc[df['Class'] == 1].values\n",
    "q25, q75 = np.percentile(v3_fraud, 25), np.percentile(v3_fraud, 75)\n",
    "v3_iqr = q75 - q25\n",
    "v3_cut_off = v3_iqr * 1.5\n",
    "v3_lower, v3_upper = q25 - v3_cut_off, q75 + v3_cut_off\n",
    "outliers = [x for x in v3_fraud if x < v3_lower or x > v3_upper]\n",
    "df = df.drop(df[(df['V3'] > v3_upper) | (df['V3'] < v3_lower)].index)\n",
    "\n",
    "##V5\n",
    "v5_fraud = df['V5'].loc[df['Class'] == 1].values\n",
    "q25, q75 = np.percentile(v5_fraud, 25), np.percentile(v5_fraud, 75)\n",
    "v5_iqr = q75 - q25\n",
    "v5_cut_off = v5_iqr * 1.5\n",
    "v5_lower, v5_upper = q25 - v5_cut_off, q75 + v5_cut_off\n",
    "outliers = [x for x in v5_fraud if x < v5_lower or x > v5_upper]\n",
    "df = df.drop(df[(df['V5'] > v5_upper) | (df['V5'] < v5_lower)].index)\n",
    "\n",
    "##V11\n",
    "v11_fraud = df['V11'].loc[df['Class'] == 1].values\n",
    "q25, q75 = np.percentile(v11_fraud, 25), np.percentile(v11_fraud, 75)\n",
    "v11_iqr = q75 - q25\n",
    "v11_cut_off = v11_iqr * 1.5\n",
    "v11_lower, v11_upper = q25 - v11_cut_off, q75 + v11_cut_off\n",
    "outliers = [x for x in v11_fraud if x < v11_lower or x > v11_upper]\n",
    "df = df.drop(df[(df['V11'] > v11_upper) | (df['V11'] < v11_lower)].index)\n",
    "\n",
    "##V15\n",
    "v15_fraud = df['V15'].loc[df['Class'] == 1].values\n",
    "q25, q75 = np.percentile(v15_fraud, 25), np.percentile(v15_fraud, 75)\n",
    "v15_iqr = q75 - q25\n",
    "v15_cut_off = v15_iqr * 1.5\n",
    "v15_lower, v15_upper = q25 - v15_cut_off, q75 + v15_cut_off\n",
    "outliers = [x for x in v15_fraud if x < v15_lower or x > v15_upper]\n",
    "df = df.drop(df[(df['V15'] > v15_upper) | (df['V15'] < v15_lower)].index)\n",
    "\n",
    "##V25\n",
    "v25_fraud = df['V25'].loc[df['Class'] == 1].values\n",
    "q25, q75 = np.percentile(v25_fraud, 25), np.percentile(v25_fraud, 75)\n",
    "v25_iqr = q75 - q25\n",
    "v25_cut_off = v25_iqr * 1.5\n",
    "v25_lower, v25_upper = q25 - v25_cut_off, q75 + v25_cut_off\n",
    "outliers = [x for x in v25_fraud if x < v25_lower or x > v25_upper]\n",
    "df = df.drop(df[(df['V25'] > v25_upper) | (df['V25'] < v25_lower)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = preprocessing.LabelEncoder() #label encoding on class_label before logistic regression\n",
    "df['Class']= label_encoder.fit_transform(df['Class']) \n",
    "df['Class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(y_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "X_adasyn, y_adasyn = ADASYN(random_state=42).fit_sample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_adasyn_train, X_adasyn_test, y_adasyn_train, y_adasyn_test = train_test_split(X_adasyn, y_adasyn, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9991874159828253\n",
      "Test accuracy: 0.9992626663389628\n",
      "Precision:0.8763,   Recall:0.6250, F1:0.7296\n",
      "CV Accuracy 0.9991187014731682\n"
     ]
    }
   ],
   "source": [
    "#Logistic regression classifier\n",
    "LR = LogisticRegression(solver= 'liblinear', fit_intercept = True)\n",
    "results_LR = LR.fit(X_adasyn_train, y_adasyn_train)\n",
    "y_pred = LR.predict(X_adasyn_test)\n",
    "print('Train accuracy:', LR.score(X_adasyn_train, y_adasyn_train))\n",
    "print('Test accuracy:', LR.score(X_adasyn_test, y_adasyn_test))\n",
    "print('Precision:{:6.4f},   Recall:{:6.4f}, F1:{:6.4f}' .format(precision_score(y_adasyn_test, y_pred), \n",
    "                                                                recall_score(y_adasyn_test, y_pred), f1_score(y_adasyn_test, y_pred)))\n",
    "CV_scores_LR = cross_val_score(LR,  X_adasyn, y_adasyn, cv=10)\n",
    "print('CV Accuracy', statistics.mean(CV_scores_LR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = svm.SVC(kernel=\"linear\")\n",
    "results_SVM = SVM.fit(X_adasyn_train, y_adasyn_train)\n",
    "y_pred_SVM = SVM.predict(X_adasyn_test)\n",
    "print('Train accuracy:', SVM.score(X_adasyn_train, y_adasyn_train))\n",
    "print('Test accuracy:', SVM.score(X_adasyn_test, y_adasyn_test))\n",
    "print('Precision:{:6.4f}, Recall:{:6.4f}, F1:{:6.4f}' .format(precision_score(y_adasyn_test, y_pred_SVM), \n",
    "                                                                recall_score(y_adasyn_test, y_pred_SVM), f1_score(y_adasyn_test, y_pred_SVM)))\n",
    "#CV_scores_SVM = cross_val_score(SVM,  X_adasyn, y_adasyn, cv=10)\n",
    "#print('CV Accuracy', statistics.mean(CV_scores_SVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Boosting Classifier\n",
    "GB = GradientBoostingClassifier()\n",
    "results_GB = GB.fit(X_adasyn_train, y_adasyn_train)\n",
    "y_pred_GB = GB.predict(X_adasyn_test)\n",
    "print('Train accuracy:', GB.score(X_adasyn_train, y_adasyn_train))\n",
    "print('Test accuracy:', GB.score(X_adasyn_test, y_adasyn_test))\n",
    "print('Precision:{:6.4f},   Recall:{:6.4f}, F1:{:6.4f}' .format(precision_score(y_adasyn_test, y_pred_GB), \n",
    "                                                                recall_score(y_adasyn_test, y_pred_GB), f1_score(y_adasyn_test, y_pred_GB)))\n",
    "CV_scores_GB = cross_val_score(GB, X_adasyn, y_adasyn, cv=10)\n",
    "print('CV Accuracy', statistics.mean(CV_scores_GB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix\n",
    "cm = confusion_matrix(y_adasyn_test, y_pred_GB)\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, ax = ax, linewidths=0.5, cmap = 'Blues_r', fmt='d')\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('True labels')\n",
    "ax.set_title('Gradient Boosting Classification')\n",
    "ax.xaxis.set_ticklabels(['No-Fraud', 'Fraud'])\n",
    "ax.yaxis.set_ticklabels(['No-Fraud', 'Fraud']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bagging Decision Tree Classification\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=7)\n",
    "cart = DecisionTreeClassifier()\n",
    "BG = BaggingClassifier(base_estimator=cart, n_estimators=100, random_state=7)\n",
    "results_BG = model_selection.cross_val_score(BG, X_adasyn_train, y_adasyn_train, cv=kfold)\n",
    "BG.fit(X_adasyn_train, y_adasyn_train)\n",
    "y_pred_BG = BG.predict(X_adasyn_test)\n",
    "print('Train accuracy:', BG.score(X_adasyn_train, y_adasyn_train))\n",
    "print('Test accuracy:', BG.score(X_adasyn_test, y_adasyn_test))\n",
    "print('Precision:{:6.4f},   Recall:{:6.4f}, F1:{:6.4f}' .format(precision_score(y_adasyn_test, y_pred_BG), \n",
    "                                                                recall_score(y_adasyn_test, y_pred_BG), f1_score(y_adasyn_test, y_pred_BG)))\n",
    "CV_scores_BG = cross_val_score(BG, X_adasyn, y_adasyn, cv=10)\n",
    "print('CV Accuracy', statistics.mean(CV_scores_BG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classification\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=7)\n",
    "RF = RandomForestClassifier(n_estimators=100, max_features=3)\n",
    "results_RF = model_selection.cross_val_score(RF, X_adasyn_train, y_adasyn_train, cv=kfold)\n",
    "RF.fit(X_adasyn_train, y_adasyn_train)\n",
    "y_pred_RF = RF.predict(X_adasyn_test)\n",
    "print('Train accuracy:', RF.score(X_adasyn_train, y_adasyn_train))\n",
    "print('Test accuracy:', RF.score(X_adasyn_test, y_adasyn_test))\n",
    "print('Precision:{:6.4f},   Recall:{:6.4f}, F1:{:6.4f}' .format(precision_score(y_adasyn_test, y_pred_RF), \n",
    "                                                                recall_score(y_adasyn_test, y_pred_RF), f1_score(y_adasyn_test, y_pred_RF)))\n",
    "CV_scores_RF = cross_val_score(RF,  X_adasyn, y_adasyn, cv=10)\n",
    "print('CV Accuracy', statistics.mean(CV_scores_RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra Trees Classification\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=7)\n",
    "ET = ExtraTreesClassifier(n_estimators=100, max_features=3)\n",
    "results_ET = model_selection.cross_val_score(ET, X_adasyn_train, y_adasyn_train, cv=kfold)\n",
    "ET.fit(X_adasyn_train, y_adasyn_train)\n",
    "y_pred_ET = ET.predict(X_adasyn_test)\n",
    "print('Train accuracy:', ET.score(X_adasyn_train, y_adasyn_train))\n",
    "print('Test accuracy:', ET.score(X_adasyn_test, y_adasyn_test))\n",
    "print('Precision:{:6.4f}, Recall:{:6.4f}, F1:{:6.4f}' .format(precision_score(y_adasyn_test, y_pred_ET), \n",
    "                                                                recall_score(y_adasyn_test, y_pred_ET), f1_score(y_adasyn_test, y_pred_ET)))\n",
    "CV_scores_ET = cross_val_score(ET,  X_adasyn, y_adasyn, cv=10)\n",
    "print('CV Accuracy', statistics.mean(CV_scores_ET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoost Classification\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=7)\n",
    "Ada = AdaBoostClassifier(n_estimators=100, random_state=7)\n",
    "results_Ada = model_selection.cross_val_score(Ada, X_adasyn_train, y_adasyn_train, cv=kfold)\n",
    "Ada.fit(X_adasyn_train, y_adasyn_train)\n",
    "y_pred_Ada = Ada.predict(X_adasyn_test)\n",
    "print('Train accuracy:', Ada.score(X_adasyn_train, y_adasyn_train))\n",
    "print('Test accuracy:', Ada.score(X_adasyn_test, y_adasyn_test))\n",
    "print('Precision:{:6.4f}, Recall:{:6.4f}, F1:{:6.4f}' .format(precision_score(y_adasyn_test, y_pred_Ada), \n",
    "                                                                recall_score(y_adasyn_test, y_pred_Ada), f1_score(y_adasyn_test, y_pred_Ada)))\n",
    "CV_scores_Ada = cross_val_score(Ada,  X_adasyn, y_adasyn, cv=10)\n",
    "print('CV Accuracy', statistics.mean(CV_scores_Ada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stochastic Gradient Boosting\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=7)\n",
    "SGB = GradientBoostingClassifier(n_estimators=100, random_state=7)\n",
    "results_SGB = model_selection.cross_val_score(SGB, X_adasyn_train, y_adasyn_train, cv=kfold)\n",
    "SGB.fit(X_adasyn_train, y_adasyn_train)\n",
    "y_pred_SGB = SGB.predict(X_adasyn_test)\n",
    "print('Train accuracy:', SGB.score(X_adasyn_train, y_adasyn_train))\n",
    "print('Test accuracy:', SGB.score(X_adasyn_test, y_adasyn_test))\n",
    "print('Precision:{:6.4f},   Recall:{:6.4f}, F1:{:6.4f}' .format(precision_score(y_adasyn_test, y_pred_SGB), \n",
    "                                                                recall_score(y_adasyn_test, y_pred_SGB), f1_score(y_adasyn_test, y_pred_SGB)))\n",
    "CV_scores_SGB = cross_val_score(SGB,  X_adasyn, y_adasyn, cv=10)\n",
    "print('CV Accuracy', statistics.mean(CV_scores_SGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting Ensemble for Classification\n",
    "estimators = []\n",
    "model1 = LogisticRegression()\n",
    "estimators.append(('logistic', model1))\n",
    "model2 = DecisionTreeClassifier()\n",
    "estimators.append(('cart', model2))\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=7)\n",
    "VC = VotingClassifier(estimators)\n",
    "results_VC = model_selection.cross_val_score(VC, X_adasyn_train, y_adasyn_train, cv=kfold)\n",
    "VC.fit(X_adasyn_train, y_adasyn_train)\n",
    "y_pred_VC = VC.predict(X_adasyn_test)\n",
    "print('Train accuracy:', VC.score(X_adasyn_train, y_adasyn_train))\n",
    "print('Test accuracy:', VC.score(X_adasyn_test, y_adasyn_test))\n",
    "print('Precision:{:6.4f},   Recall:{:6.4f}, F1:{:6.4f}' .format(precision_score(y_adasyn_test, y_pred_VC), \n",
    "                                                                recall_score(y_adasyn_test, y_pred_VC), f1_score(y_adasyn_test, y_pred_VC)))\n",
    "CV_scores_VC = cross_val_score(VC,  X_adasyn, y_adasyn, cv=10)\n",
    "print('CV Accuracy', statistics.mean(CV_scores_VC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB=xgb.XGBClassifier(random_state=7,learning_rate=0.01)\n",
    "XGB.fit(X_adasyn_train, y_adasyn_train)\n",
    "XGB.fit(X_adasyn_train, y_adasyn_train)\n",
    "y_pred_XGB = XGB.predict(X_adasyn_test)\n",
    "print('Train accuracy:', XGB.score(X_adasyn_train, y_adasyn_train))\n",
    "print('Test accuracy:', XGB.score(X_adasyn_test, y_adasyn_test))\n",
    "print('Precision:{:6.4f},   Recall:{:6.4f}, F1:{:6.4f}' .format(precision_score(y_adasyn_test, y_pred_XGB), \n",
    "                                                                recall_score(y_adasyn_test, y_pred_XGB), f1_score(y_adasyn_test, y_pred_XGB)))\n",
    "CV_scores_XGB = cross_val_score(XGB,  X_adasyn, y_adasyn, cv=10)\n",
    "print('CV Accuracy', statistics.mean(CV_scores_XGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [LR, GB, BG, RF, ET, Ada, XGB]\n",
    "ax = plt.gca()\n",
    "for i in classifiers:\n",
    "    plot_roc_curve(i, X_adasyn_test, y_adasyn_test, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [['LR', statistics.mean(CV_scores_LR),f1_score(y_adasyn_test, y_pred)],\n",
    "    ['GB', statistics.mean(CV_scores_GB),f1_score(y_adasyn_test, y_pred_GB) ],['BG', statistics.mean(CV_scores_BG), f1_score(y_adasyn_test, y_pred_BG)], \n",
    "        ['RF', statistics.mean(CV_scores_RF), f1_score(y_adasyn_test, y_pred_RF)],['ET', statistics.mean(CV_scores_ET), f1_score(y_adasyn_test, y_pred_ET)], \n",
    "        ['Ada', statistics.mean(CV_scores_Ada), f1_score(y_adasyn_test, y_pred_Ada)], ['XGB', statistics.mean(CV_scores_XGB), f1_score(y_adasyn_test, y_pred_XGB)]] \n",
    "  \n",
    "# Create the pandas DataFrame \n",
    "df = pd.DataFrame(data, columns = ['Model', 'CV_Accuracy', 'F1']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot( 'Model', 'CV_Accuracy', data=df, marker='', color='blue', linewidth=2)\n",
    "plt.plot( 'Model', 'F1', data=df, marker='', color='red', linewidth=2, linestyle='dashed', label=\"F1\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
